# LLM Platform

Building a Inference Platform which will host open source LLM models, enterprise APIs, backing off to open source and incrementally updating LLM based on new research, which will help in integrating existing backend services either as a async function or microservice.


### Tasks

- [ ] Build simple inference for oss LLM
- [ ] Expand to enterprise APIs
- [ ] make it work via CLIs
- [ ] add async functions
- [ ] build products on top of this platform e.g Rag, chatbot...